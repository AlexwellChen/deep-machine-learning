{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL3 - Intro to CNNs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Building the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "# One-hot encoding\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Callbacks for training\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "# Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Ndarray computations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data intro training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0 \n",
      "Max: 255\n"
     ]
    }
   ],
   "source": [
    "print('Min:', X_train.min(), '\\nMax:', X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 118,\n",
       "        219, 166, 118, 118,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 242, 254,\n",
       "        254, 254, 254, 254,  66,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 232, 254,\n",
       "        254, 254, 254, 254, 238,  70,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 244,\n",
       "        254, 224, 254, 254, 254, 141,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207,\n",
       "        254, 210, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84,\n",
       "        206, 254, 254, 254, 254,  41,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         24, 209, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  91,\n",
       "        137, 253, 254, 254, 254, 112,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 214, 250,\n",
       "        254, 254, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 247, 254,\n",
       "        254, 254, 254, 254, 254, 146,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 246,\n",
       "        254, 254, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  73,\n",
       "         89,  89,  93, 240, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1, 128, 254, 219,  31,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   7, 254, 254, 214,  28,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 138, 254, 254, 116,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  19, 177,  90,   0,   0,   0,   0,\n",
       "          0,  25, 240, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 164, 254, 215,  63,  36,   0,  51,\n",
       "         89, 206, 254, 254, 139,   8,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  57, 197, 254, 254, 222, 180, 241,\n",
       "        254, 254, 253, 213,  11,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 105, 254, 254, 254, 254,\n",
       "        254, 254, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 117, 117, 165, 254,\n",
       "        254, 239,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f056c972240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f056c9eefd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the input dimensions to be `[samples][width][height][channels]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize inputs to 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot-encode output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tentative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s - loss: 0.5273 - acc: 0.8663 - val_loss: 0.1956 - val_acc: 0.9449\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.1561 - acc: 0.9552 - val_loss: 0.1101 - val_acc: 0.9713\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0977 - acc: 0.9727 - val_loss: 0.0777 - val_acc: 0.9769\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0709 - acc: 0.9803 - val_loss: 0.0599 - val_acc: 0.9819\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0560 - acc: 0.9849 - val_loss: 0.0533 - val_acc: 0.9816\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0474 - acc: 0.9868 - val_loss: 0.0485 - val_acc: 0.9850\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0404 - acc: 0.9886 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0348 - acc: 0.9902 - val_loss: 0.0410 - val_acc: 0.9871\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0301 - acc: 0.9914 - val_loss: 0.0411 - val_acc: 0.9859\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0268 - acc: 0.9923 - val_loss: 0.0420 - val_acc: 0.9870\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0249 - acc: 0.9928 - val_loss: 0.0374 - val_acc: 0.9882\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0226 - acc: 0.9933 - val_loss: 0.0378 - val_acc: 0.9873\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0193 - acc: 0.9946 - val_loss: 0.0414 - val_acc: 0.9867\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0356 - val_acc: 0.9883\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 1s - loss: 0.0152 - acc: 0.9959 - val_loss: 0.0366 - val_acc: 0.9879\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = base_model()\n",
    "\n",
    "# Fit the model\n",
    "tb = TensorBoard(log_dir='./logs/initial_setting')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=1024, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def more_layers_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def more_filters_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(100, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def more_neurons_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def bnorm_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all of them and compare the results using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: more_layers_model\n",
      "Done!\n",
      "Training model: more_filters_model\n",
      "Done!\n",
      "Training model: more_neurons_model\n",
      "Done!\n",
      "Training model: bnorm_model\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model_names = ['more_layers_model', 'more_filters_model', 'more_neurons_model', 'bnorm_model']\n",
    "\n",
    "for name in model_names:\n",
    "    print('Training model:',name)\n",
    "    model = globals()[name]()\n",
    "    tb = TensorBoard(log_dir='./logs/'+name)\n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              validation_data=(X_test, y_test),\n",
    "              epochs=15, \n",
    "              batch_size=1024, \n",
    "              callbacks=[tb],\n",
    "              verbose=0)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best one and train longer. Here we also use [early stopping](https://en.wikipedia.org/wiki/Early_stopping#Validation-based_early_stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.4474 - acc: 0.8765 - val_loss: 0.1578 - val_acc: 0.9557\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.1167 - acc: 0.9669 - val_loss: 0.0753 - val_acc: 0.9767\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0702 - acc: 0.9799 - val_loss: 0.0553 - val_acc: 0.9825\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0513 - acc: 0.9852 - val_loss: 0.0473 - val_acc: 0.9852\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0419 - acc: 0.9877 - val_loss: 0.0433 - val_acc: 0.9856\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0347 - acc: 0.9897 - val_loss: 0.0392 - val_acc: 0.9870\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0309 - acc: 0.9911 - val_loss: 0.0393 - val_acc: 0.9879\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0245 - acc: 0.9932 - val_loss: 0.0351 - val_acc: 0.9888\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0225 - acc: 0.9937 - val_loss: 0.0376 - val_acc: 0.9876\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0188 - acc: 0.9948 - val_loss: 0.0324 - val_acc: 0.9890\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0160 - acc: 0.9955 - val_loss: 0.0340 - val_acc: 0.9890\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0144 - acc: 0.9963 - val_loss: 0.0323 - val_acc: 0.9891\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0339 - val_acc: 0.9888\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0108 - acc: 0.9971 - val_loss: 0.0350 - val_acc: 0.9887\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0306 - val_acc: 0.9893\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0073 - acc: 0.9985 - val_loss: 0.0349 - val_acc: 0.9885\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0063 - acc: 0.9988 - val_loss: 0.0353 - val_acc: 0.9891\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0053 - acc: 0.9990 - val_loss: 0.0308 - val_acc: 0.9896\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0356 - val_acc: 0.9884\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0046 - acc: 0.9993 - val_loss: 0.0343 - val_acc: 0.9893\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0036 - acc: 0.9994 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0030 - acc: 0.9996 - val_loss: 0.0358 - val_acc: 0.9892\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0357 - val_acc: 0.9895\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0362 - val_acc: 0.9893\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0351 - val_acc: 0.9900\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0338 - val_acc: 0.9901\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0365 - val_acc: 0.9901\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0377 - val_acc: 0.9889\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0352 - val_acc: 0.9907\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0361 - val_acc: 0.9897\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s - loss: 9.8581e-04 - acc: 0.9999 - val_loss: 0.0361 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s - loss: 9.1153e-04 - acc: 0.9999 - val_loss: 0.0362 - val_acc: 0.9899\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s - loss: 8.9771e-04 - acc: 0.9999 - val_loss: 0.0358 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s - loss: 8.2922e-04 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9899\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s - loss: 8.1615e-04 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05003c1710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = more_filters_model()\n",
    "\n",
    "# Set callbacks\n",
    "tb = TensorBoard(log_dir='./logs/final_model')\n",
    "estop = EarlyStopping(monitor='val_acc', patience=5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=1024, callbacks=[tb, estop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate accuracy on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
